---
title: "MLHC Final Project"
author: "Xinmi Li"
date: "April 25, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(scipen=999)
```

Load libraries
```{r}
library(plyr)
library(dplyr)
library(ggplot2)
library(data.table)
library(mice)
library(Amelia)
library(bnlearn)
library(rpart)
library(rpart.plot)
library(randomForest)
library(caret)
library(ROCR)
```

Load tables with needed data
```{r}
adm <- data.frame(read.csv(file = "/Users/Xinmi/git/MLforHC_FinalProject/adm.csv", header = TRUE))
adm.original <- data.frame(read.csv(file = "/Users/Xinmi/git/MLforHC_FinalProject/ADMISSIONS.csv", header = TRUE))
ds <- data.frame(read.csv(file = "/Users/Xinmi/git/MLforHC_FinalProject/ds.csv", header = TRUE))
pts <- data.frame(read.csv(file = "/Users/Xinmi/git/MLforHC_FinalProject/pts.csv", header = TRUE))
surgpts <- data.frame(read.csv(file = "/Users/Xinmi/git/MLforHC_FinalProject/surgpts.csv", header = TRUE))
rx <- fread("/Users/Xinmi/git/MLforHC_FinalProject/PRESCRIPTIONS.csv", header = T, sep = ",") %>% 
  select(SUBJECT_ID, HADM_ID, DRUG, FORMULARY_DRUG_CD)%>% 
  filter(SUBJECT_ID %in% surgpts$SUBJECT_ID)
cesurg <- fread('/Users/Xinmi/git/MLforHC_FinalProject/cesurg.csv', header = T, sep = ',')
```


Data pre-processing
```{r}
# Clean the table to leave only the most recent admission for each patient
adm2 <- adm.original %>% 
  filter(SUBJECT_ID %in% adm$SUBJECT_ID) %>% 
  group_by(SUBJECT_ID) %>%
  filter(as.numeric(ADMITTIME) == max(as.numeric(ADMITTIME))) %>%
  select(SUBJECT_ID, HADM_ID, DIAGNOSIS)

# Since multiple diagnoses are assigned with one patient, and the SEQ_NUM shows the priority of diagnoses, here only the prior diagnosis is kept.
ds2 <- ds %>%
  select(SUBJECT_ID, HADM_ID, SEQ_NUM, ICD9_CODE, SHORT_TITLE) %>% 
  filter(HADM_ID %in% adm2$HADM_ID & SEQ_NUM == 1)

rx2 <- rx %>%
  select(SUBJECT_ID, HADM_ID, DRUG, FORMULARY_DRUG_CD) %>% 
  filter(HADM_ID %in% adm2$HADM_ID)

# Select only the top 10 commonly used drugs (based on drug code)
drug10 <- table(rx2$FORMULARY_DRUG_CD) %>%
  sort(decreasing = TRUE) %>%
  names() %>%
  head(10)
  
rx3 <- rx2 %>%
  filter(FORMULARY_DRUG_CD == drug10)

rx4 <- cbind(rx3[,1:3], model.matrix( ~ FORMULARY_DRUG_CD - 1, data=rx3)) %>%
  select(-DRUG)

SUBJECT_ID <- unique(rx4$SUBJECT_ID)
rx4.list <- do.call(rbind, by(rx4[,c(3:12)], rx4$SUBJECT_ID, FUN=colSums))
rx4.table <- as.data.frame(cbind(SUBJECT_ID, rx4.list))

# One patient can be given the same drug multiple times during one admission. Since we only care whether the patient is given this drug, all non-zero numbers in drug columns are mapped to 1.

rx5 <- cbind(SUBJECT_ID, apply(rx4.table[,2:11], 2, FUN = function(x) {as.numeric(x!=0)})) %>%
  as.data.frame()
colnames(rx5) <- c("SUBJECT_ID","D5W250", "FURO40I", "INSULIN", "LR1000", "MAG2PM", "METO5I", 
                          "NACLFLUSH", "NS1000", "NS250", "NS500")

# Select some vitals (based on references) from chart events and transform them to average value for each patient.
cesurg2 <- cesurg %>%
  select(SUBJECT_ID, HADM_ID, ITEMID, VALUE, VALUENUM, VALUEUOM, LABEL) %>% 
  filter(HADM_ID %in% adm2$HADM_ID)

cesurg2.RR <- subset(cesurg2, grepl("Respiratory Rate", cesurg2$LABEL, ignore.case = TRUE))
cesurg2.RR.aggr <- aggregate(VALUENUM ~ SUBJECT_ID, data = cesurg2.RR, FUN = mean)
colnames(cesurg2.RR.aggr)[2] <- "RR"

cesurg2.SPO2 <- subset(cesurg2, grepl("SpO2", cesurg2$LABEL, ignore.case = TRUE))
cesurg2.SPO2.aggr <- aggregate(VALUENUM ~ SUBJECT_ID, data = cesurg2.SPO2, FUN = mean)
colnames(cesurg2.SPO2.aggr)[2] <- "SPO2"

cesurg2.T <- subset(cesurg2, grepl("Temperature F", cesurg2$LABEL, ignore.case = TRUE))
cesurg2.T.aggr <- aggregate(VALUENUM ~ SUBJECT_ID, data = cesurg2.T, FUN = mean)
colnames(cesurg2.T.aggr)[2] <- "T"

cesurg2.BP <- subset(cesurg2, grepl("BP Systolic", cesurg2$LABEL, ignore.case = TRUE))
cesurg2.BP.aggr <- aggregate(VALUENUM ~ SUBJECT_ID, data = cesurg2.BP, FUN = mean)
colnames(cesurg2.BP.aggr)[2] <- "BP"

cesurg2.HR <- subset(cesurg2, grepl("Heart Rate", cesurg2$LABEL, ignore.case = TRUE))
cesurg2.HR.aggr <- aggregate(VALUENUM ~ SUBJECT_ID, data = cesurg2.HR, FUN = mean) 
colnames(cesurg2.HR.aggr)[2] <- "HR"

# Combine the tables into one 
df <- pts %>%
  inner_join(adm2 %>% select(DIAGNOSIS), by="SUBJECT_ID") %>%
  left_join(ds2 %>% select(SUBJECT_ID, ICD9_CODE, SHORT_TITLE), by="SUBJECT_ID") %>%
  left_join(rx5, by="SUBJECT_ID")  %>%
  left_join(cesurg2.RR.aggr, by="SUBJECT_ID") %>%
  left_join(cesurg2.SPO2.aggr, by="SUBJECT_ID") %>%
  left_join(cesurg2.T.aggr, by="SUBJECT_ID") %>%
  left_join(cesurg2.BP.aggr, by="SUBJECT_ID") %>%
  left_join(cesurg2.HR.aggr, by="SUBJECT_ID") 
```


Process missing values
```{r, cache=TRUE}
# Check the missing values
md.pattern(df)

# Drop patients with more than 5 missing items and colomns with over 50% missing values
df2 <- df[-which(rowSums(is.na(df)) > 5),-which(colMeans(is.na(df)) > 0.5)]
md.pattern(df2)

# Since ICD-9 Code and Short Title (description) cannot be imputed, the 47 patients with only these two missing items are also dropped.
df3 <- df2[-which(is.na(df2$ICD9_CODE)),]

# Categorizing the patients based on ICD-9 Code Groups (first 3 digits), drop patients with V Codes (Supplemental Codes, unable to categorize).
df4 <- df3 %>% 
  subset(!grepl("V", df3$ICD9_CODE))

ICD.break <- c(001, 140, 240, 280, 290, 320, 390, 460, 520, 580, 630, 680, 710, 740, 760, 
               780, 790, 797, 800, 999)

df4$ICD9_CODE <- substr(df4$ICD9_CODE, 0, 3) %>%
  as.numeric() %>%
  cut(breaks = ICD.break, include.lowest=TRUE)

df4[sapply(df4, (function(x) length(unique(x))<3))]  <-
  lapply(df4[,sapply(df4, (function(x) length(unique(x))<3))], as.factor)

# Impute missing values
df5 <- amelia(df4, m = 5, p2s = 0, idvars = names(df4[,1:16]))$imputations[[5]]
md.pattern(df4)
md.pattern(df5)
# By comparing the missing patterns of data with/without imputation, 61 patients still have missing values unable to be imputed, so they are dropped.
df6 <- na.omit(df5) %>%
  select(-SUBJECT_ID, -DIAGNOSIS, -SHORT_TITLE)

# Get train and test sets
set.seed(123456789)
index <- sample(1:nrow(df6))[1:floor(0.5*nrow(df6))]
train <- df6[index, ]
test <- df6[-index, ]

df6.d <- discretize(df6)
train.d <- df6.d[index, ]
test.d <- df6.d[-index, ]

# Remove the row in train/test set with level of ICD9_CODE not seen in the other set (unable to predict in bayes learn) and drop the unused levels. To be fair, all train and test sets will drop the same rows.
test.drop <- 0
for (i in 1:nrow(test.d)) {
    if (!(test.d[i,3] %in% train.d[,3])) {
      test.drop <- c(test.drop, i)
    }
  }


if (length(test.drop)>1) {
  test.d2 <- test.d[-test.drop[-1],] %>%
    droplevels.data.frame
  test2 <- test[-test.drop[-1],]
} else {
  test.d2 <- test.d %>%
    droplevels.data.frame
  test2 <- test
}  

train.drop <- 0
for (j in 1:nrow(train.d)) {
    if (!(train.d[j,3] %in% test.d2[,3])) {
      train.drop <- c(train.drop, j)
    }
}

if (length(train.drop)>1) {
  train.d2 <- train.d[-train.drop[-1],] %>%
    droplevels.data.frame
  train2 <- train[-train.drop[-1],]
} else {
  train.d2 <- train.d %>%
    droplevels.data.frame
  train2 <- test
} 

# Death rate in train and test sets
round((sum(as.numeric(train2$EXPIRE_FLAG == 1)))/nrow(train2), 2)
round((sum(as.numeric(test2$EXPIRE_FLAG == 1)))/nrow(test2), 2)
```


Build models
```{r, cache=TRUE}
# Logistic Regression
lr <- glm(EXPIRE_FLAG == 1 ~ .,
          family=binomial(link="logit"), data = train2)
summary(lr)

# Show and plot variable importance
imp.lr <- cbind.data.frame(Variable = rownames(varImp(lr)), 
                 Importance = as.numeric(varImp(lr)$Overall)) %>%
  arrange(desc(Importance))

ggplot() +
  geom_point(data = imp.lr, aes(x = Importance, y = Variable), size = 2)

# Select variables that only significant at the 0.05 level.
lr2 <- glm(EXPIRE_FLAG == 1 ~ ICD9_CODE + RR + SPO2 + T,
          family=binomial(link="logit"), data = train2)
summary(lr2)

# Show and plot variable importance
imp.lr2 <- cbind.data.frame(Variable = rownames(varImp(lr2)), 
                 Importance = as.numeric(varImp(lr2)$Overall)) %>%
  arrange(desc(Importance))

ggplot() +
  geom_point(data = imp.lr2, aes(x = Importance, y = Variable), size = 2)


# Test the model
predict.lr <- predict(lr2, test2)

summary.lr <- as.vector(predict.lr>=0.5) %>%
  table(test2$EXPIRE_FLAG)
summary.lr

accuracy.lr <- (summary.lr[1,1]+summary.lr[2,2])/sum(colSums(summary.lr))
error.lr <- 1 - accuracy.lr
CI.lr.lower <- accuracy.lr - 1.96 * sqrt(error.lr*accuracy.lr/sum(colSums(summary.lr)))
CI.lr.upper <- accuracy.lr + 1.96 * sqrt(error.lr*accuracy.lr/sum(colSums(summary.lr)))
```

```{r, cache=TRUE}
# Naive Bayes
nb <- naive.bayes(train.d2, "EXPIRE_FLAG")
fitted.nb <- bn.fit(nb, train.d2)
summary(nb)

# Test the model
predict.nb <- predict(fitted.nb, test.d2, prob = TRUE)

summary.nb <- predict.nb %>% 
  table(test.d2$EXPIRE_FLAG)
summary.nb

accuracy.nb <- (summary.nb[1,1]+summary.nb[2,2])/sum(colSums(summary.nb))
error.nb <- 1 - accuracy.nb
CI.nb.lower <- accuracy.nb - 1.96 * sqrt(error.nb*accuracy.nb/sum(colSums(summary.nb)))
CI.nb.upper <- accuracy.nb + 1.96 * sqrt(error.nb*accuracy.nb/sum(colSums(summary.nb)))
```


```{r, cache=TRUE}
# Tree Augmented Naive Bayes
tan <- tree.bayes(train.d2, "EXPIRE_FLAG")
fitted.tan <- bn.fit(tan, train.d2)
summary(tan)

# Test the model
predict.tan <- predict(fitted.tan, test.d2, prob = TRUE)

summary.tan <- predict.tan %>% 
  table(test.d2$EXPIRE_FLAG)
summary.tan

accuracy.tan <- (summary.tan[1,1]+summary.tan[2,2])/sum(colSums(summary.tan))
error.tan <- 1 - accuracy.tan
CI.tan.lower <- accuracy.tan - 1.96 * sqrt(error.tan*accuracy.tan/sum(colSums(summary.tan)))
CI.tan.upper <- accuracy.tan + 1.96 * sqrt(error.tan*accuracy.tan/sum(colSums(summary.tan)))
```


```{r, cache=TRUE}
# Decision Tree
# Build the tree with the loosest constraints. 
dt <- rpart(EXPIRE_FLAG ~ ., data = train.d2, control=rpart.control(minsplit=2, minbucket=1, cp=0.001))
printcp(dt)
print(dt)
plotcp(dt)

# Prune the tree to minimize the cross-validation error.
dt2 <- prune(dt, cp = dt$cptable[which.min(dt$cptable[,"xerror"]),"CP"])
printcp(dt2)
print(dt2)
plotcp(dt2)

# Plot the tree and show variable importance
rpart.plot(dt2)
imp.dt2 <- cbind.data.frame(Variable = rownames(varImp(dt2)), 
                 Importance = as.numeric(varImp(dt2)$Overall)) %>%
  arrange(desc(Importance))

ggplot() +
  geom_point(data = imp.dt2, aes(x = Importance, y = Variable), size = 2)


# Test the model.
predict.dt <- predict(dt2, test.d2) %>%
  as.data.frame
  
prediction.dt <- apply(predict.dt, 1, function(x){x[2] > x[1]})

summary.dt <- as.vector(prediction.dt) %>% 
  table(test.d2$EXPIRE_FLAG)
summary.dt

accuracy.dt <- (summary.dt[1,1]+summary.dt[2,2])/sum(colSums(summary.dt))
error.dt <- 1 - accuracy.dt
CI.dt.lower <- accuracy.dt - 1.96 * sqrt(error.dt*accuracy.dt/sum(colSums(summary.dt)))
CI.dt.upper <- accuracy.dt + 1.96 * sqrt(error.dt*accuracy.dt/sum(colSums(summary.dt)))
```


```{r, cache=TRUE}
# Random Forest
set.seed(123456789)
rf <- randomForest(EXPIRE_FLAG ~ ., data = train.d2, importance = TRUE, ntree = 1000)
varImpPlot(rf, main = "Importance of variables")

predict.rf <- predict(rf, test.d2)

summary.rf <- predict.rf %>% 
  table(test.d2$EXPIRE_FLAG)
summary.rf

accuracy.rf <- (summary.rf[1,1]+summary.rf[2,2])/sum(colSums(summary.rf))
error.rf <- 1 - accuracy.rf
CI.rf.lower <- accuracy.rf - 1.96 * sqrt(error.rf*accuracy.rf/sum(colSums(summary.rf)))
CI.rf.upper <- accuracy.rf + 1.96 * sqrt(error.rf*accuracy.rf/sum(colSums(summary.rf)))
```


Model comparison
```{r}
# Accuracy
data.frame(Method = c("Logistic Regression", "Naive Bayes", "Tree Augmented Bayes", 
                      "Decision Tree", "Random Forest"),
           Accuracy = c(accuracy.lr, accuracy.nb, accuracy.tan, accuracy.dt, accuracy.rf),
           CI.Lower = c(CI.lr.lower, CI.nb.lower, CI.tan.lower, CI.dt.lower, CI.rf.lower),
           CI.Upper = c(CI.lr.upper, CI.nb.upper, CI.tan.upper, CI.dt.upper, CI.rf.upper))

# ROC Curve
perform.lr <- prediction(predict.lr, test2$EXPIRE_FLAG) %>% 
  performance("tpr", "fpr")
ROC.lr <- data.frame(y = perform.lr@y.values[[1]], x = perform.lr@x.values[[1]], 
                     method = "Logistic Regression")
perform.nb <- prediction(attr(predict.nb,"prob")[2,], test.d2$EXPIRE_FLAG) %>% 
  performance("tpr", "fpr")
ROC.nb <- data.frame(y = perform.nb@y.values[[1]], x = perform.nb@x.values[[1]], 
                     method = "Naive Bayes")
perform.tan <- prediction(attr(predict.tan,"prob")[2,], test.d2$EXPIRE_FLAG) %>% 
  performance("tpr", "fpr")
ROC.tan <- data.frame(y = perform.tan@y.values[[1]], x = perform.tan@x.values[[1]], 
                     method = "Tree Augmented Bayes")
perform.dt <- prediction(predict.dt[,2], test.d2$EXPIRE_FLAG) %>% 
  performance("tpr", "fpr")
ROC.dt <- data.frame(y = perform.dt@y.values[[1]], x = perform.dt@x.values[[1]], 
                     method = "Decision Tree")
perform.rf <- prediction(rf$votes[,2], test.d2$EXPIRE_FLAG) %>% 
  performance("tpr", "fpr")  
ROC.rf <- data.frame(y = perform.rf@y.values[[1]], x = perform.rf@x.values[[1]], 
                     method = "Random Forest")

ROC <- rbind(ROC.lr, ROC.nb, ROC.tan, ROC.dt, ROC.rf)

ggplot(data = ROC, aes(x = x, y = y, color = factor(method))) +
  geom_point(size = 0.01) + xlim(0, 1) +
  xlab("False Positive Rate") + ylab("True Positive Rate")

# PR Curve
perform2.lr <- prediction(predict.lr, test2$EXPIRE_FLAG) %>% 
  performance("prec", "rec")
PR.lr <- data.frame(y = perform2.lr@y.values[[1]], x = perform2.lr@x.values[[1]], 
                     method = "Logistic Regression")
perform2.nb <- prediction(attr(predict.nb,"prob")[2,], test.d2$EXPIRE_FLAG) %>% 
  performance("prec", "rec")
PR.nb <- data.frame(y = perform2.nb@y.values[[1]], x = perform2.nb@x.values[[1]], 
                     method = "Naive Bayes")
perform2.tan <- prediction(attr(predict.tan,"prob")[2,], test.d2$EXPIRE_FLAG) %>% 
  performance("prec", "rec")
PR.tan <- data.frame(y = perform2.tan@y.values[[1]], x = perform2.tan@x.values[[1]], 
                     method = "Tree Augmented Bayes")
perform2.dt <- prediction(predict.dt[,2], test.d2$EXPIRE_FLAG) %>% 
  performance("prec", "rec")
PR.dt <- data.frame(y = perform2.dt@y.values[[1]], x = perform2.dt@x.values[[1]], 
                     method = "Decision Tree")
perform2.rf <- prediction(rf$votes[,2], test.d2$EXPIRE_FLAG) %>% 
  performance("prec", "rec")  
PR.rf <- data.frame(y = perform2.rf@y.values[[1]], x = perform2.rf@x.values[[1]], 
                     method = "Random Forest")

PR <- rbind(PR.lr, PR.nb, PR.tan, PR.dt, PR.rf)

ggplot(data = PR, aes(x = x, y = y, color = factor(method))) +
  geom_point(size = 0.01) + xlim(0, 1) +
  xlab("Recall") + ylab("Precision")
```

# Some codes for paper use
```{r}
# Cohort Stat
table(df$GENDER, df$EXPIRE_FLAG)
aggregate(RR ~ GENDER + EXPIRE_FLAG, data = df, FUN = mean)
aggregate(SPO2 ~ GENDER + EXPIRE_FLAG, data = df, FUN = mean)
aggregate(T ~ GENDER + EXPIRE_FLAG, data = df, FUN = mean)
aggregate(BP ~ GENDER + EXPIRE_FLAG, data = df, FUN = mean)
aggregate(HR ~ GENDER + EXPIRE_FLAG, data = df, FUN = mean)
```
